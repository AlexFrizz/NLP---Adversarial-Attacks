# NLP---Adversarial-Attacks

Gli adversarial attack rappresentano una sfida significativa nel campo del Natural Language Processing (NLP), evidenziando vulnerabilità critiche nei sistemi di elaborazione del linguaggio naturale. 
Questo studio presenta un’analisi comparativa dell’efficacia degli attacchi avversari su due diverse architetture: i classificatori tradizionali e i modelli neurali. 
La ricerca si concentra sulla valutazione delle principali metodologie di attacco, fornendo prima una panoramica generale del problema, ed esaminando le differenze nelle strategie di perturbazione e dei loro effetti su sistemi con architetture fondamentalmente diverse.
